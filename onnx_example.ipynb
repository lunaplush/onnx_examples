{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cd74640-8431-4baa-be82-6285d62444e8",
   "metadata": {},
   "source": [
    "# Open Neural Network Exchange  (**ONNX**)\n",
    "![ONNX](ONNX-Logo.svg)\n",
    "ONNX – открытый стандарт для конвертации моделей машинного обучения из разных фреймворков в единый формат, а также для обмена моделями между фреймворками\n",
    "\n",
    "Пример сохранения модели ElKulako/cryptobert в onnx формате и оценка измнения скорости инференса в PyTorch и ONNX.\n",
    "\n",
    "\n",
    "[Ссылка на ElKulako/cryptobert модель на Huggingface ](https://huggingface.co/ElKulako/cryptobert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bef42a9-e3f5-4244-b9c9-f36b4817261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, time\n",
    "from transformers import TextClassificationPipeline, AutoTokenizer, AutoModelForSequenceClassification \n",
    "import torch, onnx\n",
    "import onnxruntime\n",
    "from onnxruntime import InferenceSession, SessionOptions\n",
    "from onnxruntime.capi.onnxruntime_pybind11_state import InvalidArgument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f45cd8-efa9-4d53-b5df-bb57c336dbfb",
   "metadata": {},
   "source": [
    "1. Используем библиотеку transformers от HuggingFace для работы с моделью\n",
    "Флаг FLAG_SOFT_USE == True : Преобразуем logits выходы нейронной сети в оценки настроения новости с \n",
    "                             помощью функции Softmax\n",
    "Флаг FLAG_SOFT_USE == False : Функция Softmax  не применяется "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e8c6fa-bfd2-4493-8f63-bc616f5fe16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_SOFTMAX_USE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "627f2947-9ebb-4f82-a375-c44905e9281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ElKulako/cryptobert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast = False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 3)\n",
    "pipeline =  TextClassificationPipeline(model=model, tokenizer=tokenizer, max_length=64, truncation=True, padding='max_length', top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03cf566c-7729-4046-9942-63091fda1a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 новостей обработано за 0.6470144с без softmax \n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "news_list = [\"How the GBTC premium commerce ruined Barry Silbert, his DCG empire and took crypto lending platforms with them\",\n",
    "             \"MicroStrategy’s Bitcoin Strategy Sets Tongues Wagging Even As It Doubles Down On BTC Purchases ⋆ ZyCrypto\",\n",
    "             \"How the GBTC premium trade ruined Barry Silbert, his DCG empire and took crypto lending platforms with them\",\n",
    "             \"Bitcoin Holders To Expect More Difficulties As Data Point To Looming BTC Price Drop\",\n",
    "             \"Bitcoin Breaks Past $17,000 Barrier – Will BTC Also Breach 4% Weekly Run?\",\n",
    "             \"Bitcoin Price Today 9 Jan: BTC Increases By 1.79% Painting The Chart Green\",\n",
    "             \"Bitcoin: This is what large investor and retail interest can do for BTC over time\"                          \n",
    "]\n",
    "pytorch_output = []\n",
    "for n in news_list:\n",
    "    if FLAG_SOFTMAX_USE:\n",
    "        pytorch_output.append(pipeline(n))\n",
    "    # Результат работы модели без преобразования  logits функцией softmax\n",
    "    else:        \n",
    "         input_ids = torch.tensor(tokenizer.encode(n)).unsqueeze(0)\n",
    "         pytorch_output.append(model(input_ids))\n",
    "t_torch = time.time() - t_start\n",
    "    \n",
    "print(\"{} новостей обработано за {:.7f}с {} \".format(len(news_list), t_torch, (\"с softmax\"  if FLAG_SOFTMAX_USE else \"без softmax\")))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed09401-7358-43a7-be4e-08907ebc9c0b",
   "metadata": {},
   "source": [
    "2. Конвертируем Cryptobert модель в onnx-формат и сохраняем в файл bert.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba3761e2-9c10-4cb5-b262-6516dd08c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model_input = tokenizer(\n",
    "        \"текст для конвертации\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cpu\")\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_model_input[\"input_ids\"],\n",
    "    \"bert.onnx\",\n",
    "    opset_version=12,\n",
    "    input_names=[\"input_ids\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {\n",
    "            0: \"batch_size\",\n",
    "            1: \"sequence_len\"\n",
    "        },\n",
    "        \"output\": {\n",
    "            0: \"batch_size\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7d6cf-a931-417a-bcdb-3d6f463ef584",
   "metadata": {},
   "source": [
    "3. Выполняем инференс с помощью onnxruntime\n",
    "ONNX Runtime – библиотека для кроссплатформенного ускорения обучения и инференса моделей;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a273403d-a4e1-4756-80f3-941411734052",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = SessionOptions()\n",
    "options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "options.intra_op_num_threads = 1\n",
    "session = InferenceSession(\"bert.onnx\", options, providers=[\"CPUExecutionProvider\"])\n",
    "session.disable_fallback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb934ff-b23b-40d9-99be-90b1de5d8b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    logits = np.exp(logits)\n",
    "    s = sum(logits)\n",
    "    for i in range(3):\n",
    "        logits[i]=logits[i]/s\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff458761-5e32-4f3a-9b7c-7339292a1f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 новостей обработано за 0.5392591953277588c без softmax\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "onnx_output = []\n",
    "for n in news_list:   \n",
    "    inputs = tokenizer(n)    \n",
    "    input_feed = {\"input_ids\":np.array(inputs[\"input_ids\"]).reshape(1,-1)}\n",
    "    try:\n",
    "        output = session.run(\n",
    "             output_names=[\"output\"],\n",
    "             input_feed=input_feed\n",
    "        )[0][0]\n",
    "        if FLAG_SOFTMAX_USE:\n",
    "            output = softmax(output)            \n",
    "        onnx_output.append(output)\n",
    "    except (RuntimeError, InvalidArgument) as e:\n",
    "        print(e) \n",
    "  \n",
    "   # str =\"{:.6f}, {:.6f}, {:.6f}\".format(output[0], output[1], output[2])) after softmax\n",
    "t_onnx = time.time() - t_start\n",
    "print(\"{} новостей обработано за {}c {}\".format(len(news_list), t_onnx, (\"с softmax\"  if FLAG_SOFTMAX_USE else \"без softmax\") ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f933112-34a0-4782-a076-46a11ddd2665",
   "metadata": {},
   "source": [
    "Оценим время инференса Pytorch и ONNX моделей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef839946-891d-4190-bfc1-ead1161b2763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат работы модели без softmax \n",
      "Onnx модель работает на 0.107755c быстрее, то есть в 1.20 раз быстрее : onnx 0.539259c против pytorch 0.647014c\n"
     ]
    }
   ],
   "source": [
    "print(\"Результат работы модели {} \".format(\"с softmax\"  if FLAG_SOFTMAX_USE else \"без softmax\"))\n",
    "print(\"Onnx модель работает на {:.6f}c быстрее, то есть в {:.2f} раз быстрее : onnx {:.6f}c против pytorch {:.6f}c\".format(t_torch-t_onnx, t_torch/t_onnx, t_onnx, t_torch ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c490f-10fe-431e-a790-f0d1c4f07f44",
   "metadata": {},
   "source": [
    "Проверим результа работы инфренса Pytorch и ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a374bb8-cf82-4711-b46f-c7fe80ca3b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits (без oftmax)\n",
      "((-4.98122, 2.5637887, 1.7561779), array([-4.9812217,  2.5637898,  1.7561791], dtype=float32))\n",
      "((-3.2925947, 1.5659943, 1.4243592), array([-3.2925928,  1.5659933,  1.4243565], dtype=float32))\n",
      "((-4.9118767, 2.8916512, 1.3431506), array([-4.9118824,  2.8916552,  1.343152 ], dtype=float32))\n",
      "((-4.230209, 1.903221, 1.9884388), array([-4.2302027,  1.9032187,  1.988435 ], dtype=float32))\n",
      "((-2.0214012, 1.0943921, 1.3000424), array([-2.0214126,  1.0943971,  1.3000479], dtype=float32))\n",
      "((-3.1212604, 1.6515594, 1.3943415), array([-3.121268 ,  1.6515632,  1.3943424], dtype=float32))\n",
      "((0.09347219, 0.21490246, -0.15068218), array([ 0.09346019,  0.2149083 , -0.15067741], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "if FLAG_SOFTMAX_USE:\n",
    "    print(\"C softmax\")\n",
    "   \n",
    "    pytorch_output_ch = []\n",
    "    for i in range(len(pytorch_output)):\n",
    "        for j in range(3):\n",
    "            a = pytorch_output[i][0][j]\n",
    "            if a[\"label\"] == \"Neutral\":\n",
    "               a2 = a[\"score\"]\n",
    "            if a[\"label\"] == \"Bullish\":\n",
    "               a3 = a[\"score\"]\n",
    "            if a[\"label\"] == \"Bearish\":\n",
    "               a1 = a[\"score\"]\n",
    "        pytorch_output_ch.append((a1,a2,a3))   \n",
    "    \n",
    "else:\n",
    "    print(\"Logits (без oftmax)\")\n",
    "    pytorch_output_ch = []\n",
    "    for i in range(len(pytorch_output)):\n",
    "        a = pytorch_output[i].logits.detach().numpy()[0]\n",
    "        pytorch_output_ch.append((a[0],a[1],a[2]))\n",
    "    \n",
    "b = list(zip(pytorch_output_ch,onnx_output)) \n",
    "[print(i) for i in b];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150c482-f24d-4168-a88d-03650c312050",
   "metadata": {},
   "source": [
    "Результат работы модели без softmax совпадает до 5 знака после запятой."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gan",
   "language": "python",
   "name": "venv_gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
